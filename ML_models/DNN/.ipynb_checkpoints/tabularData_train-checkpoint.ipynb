{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, concatenate, Flatten\n",
    "from keras.layers.core import Dense, Reshape, Lambda\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow import set_random_seed\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "BASE_DIR = \"../..\"\n",
    "DATA_DIR = \"data\"\n",
    "DATA_FILE = \"balanced_data.csv\"\n",
    "WORD_EMBEDDING_DIM = 100\n",
    "GLOVE_DIR = \"glove.6B\"\n",
    "GLOVE_FILE = \"glove.6B.\" +  str(WORD_EMBEDDING_DIM) + 'd.txt'\n",
    "#GLOVE_WORDS = 400000\n",
    "GLOVE_VOCSIZE = 400000\n",
    "INS_USERNAME_EMBEDDING_DIM = 20\n",
    "MAX_WORDS_IN_CAPTION = 40\n",
    "SPLIT_RATIO = [0.7, 0.15, 0.15] # training : validation : test\n",
    "\n",
    "data_path = os.path.join(BASE_DIR, DATA_DIR, DATA_FILE)\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1337\n",
      "5\n",
      "6\n",
      "6\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "N_ins_username = data.poster_instagram_username.nunique()\n",
    "N_poster_account_type = data.poster_account_type.nunique()\n",
    "N_media_type =data.media_type.nunique()\n",
    "N_caption_type = data.caption_type.nunique()\n",
    "\n",
    "raw_input_dim = MAX_WORDS_IN_CAPTION + 1 + \\\n",
    "                N_poster_account_type + N_media_type + N_caption_type\n",
    "\n",
    "print(N_ins_username)\n",
    "print(N_poster_account_type)\n",
    "print(N_media_type)\n",
    "print(N_caption_type)\n",
    "print(raw_input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the tabular data to usable numerial data to feed in the network\n",
    "## Transform caption and username data -- for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../glove.6B/glove.6B.100d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8174a6f58d3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mglove_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGLOVE_DIR\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mGLOVE_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mglove_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxsplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../glove.6B/glove.6B.100d.txt'"
     ]
    }
   ],
   "source": [
    "# build word : vec dictionary from GloVe\n",
    "glove_path = os.path.join(BASE_DIR, GLOVE_DIR,  GLOVE_FILE)\n",
    "glove_index = {}\n",
    "with open(glove_path) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, dtype = 'float', sep=' ')\n",
    "        glove_index[word] = coefs\n",
    "\n",
    "# prepare tokenizer\n",
    "captions = data.media_caption.astype(str)\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(captions)\n",
    "vocab_size = len(token.word_index) + 1 # word_index is 1-indexed, puls 1-dim for OOV and padded words\n",
    "print(\"The size of the vocabulary is: \", vocab_size)\n",
    "\n",
    "# integer encode the documents\n",
    "encoded_captions = token.texts_to_sequences(captions)\n",
    "# pad documents to a max length of 4 words\n",
    "padded_captions = pad_sequences(encoded_captions, maxlen=MAX_WORDS_IN_CAPTION, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use \"represented_data\" matrix, to store the encoded data\n",
    "represented_data = padded_captions.copy()\n",
    "\n",
    "# create a weight matrix for all words in captions\n",
    "embedding_matrix = np.zeros((vocab_size, WORD_EMBEDDING_DIM))\n",
    "for word, idx in token.word_index.items(): # word_index is 1-indexed, zero vector for padding\n",
    "    embedding_vector = glove_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[idx] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poster_instagram_username N_ins_username dim categorial, needs to be embedded to INS_USERNAME_EMBEDDING_DIM dim\n",
    "def OrdinalEncoder(categories):\n",
    "    \"\"\" An ordinal Encoder for data pre-processing,\n",
    "        Not strictly ordinal, but does the work.\n",
    "    \n",
    "        Args:\n",
    "            categories: numpy arrary or list of categories              \n",
    "        Returns:\n",
    "            numpy array of ordinal encoded entries        \n",
    "    \"\"\"\n",
    "    counter = Counter(categories).most_common() # indices assigned based on number of occurances\n",
    "    unique_ctgrs = [x[0] for x in counter] # list of categories, guaranteed in fixed order due to sorting\n",
    "    encoder = {ctgr : idx for idx, ctgr in enumerate(unique_ctgrs)}\n",
    "        \n",
    "    res = [0] * len(categories)\n",
    "    res = [encoder[ctgr] for ctgr in categories]\n",
    "    return np.array(res, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_usernames = data.poster_instagram_username\n",
    "encoded_ins_usernames = OrdinalEncoder(ins_usernames)\n",
    "encoded_ins_usernames = np.array(encoded_ins_usernames).reshape(-1, 1)\n",
    "# concatenate encoded_ins_usernames to represented_data\n",
    "represented_data = np.concatenate((represented_data, encoded_ins_usernames), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(represented_data))\n",
    "print(len(represented_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform poster_account_type, media_type and caption_type -- one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ctgr in ['poster_account_type', 'media_type', 'caption_type']:\n",
    "    col=data[ctgr]\n",
    "    one_hot_encoded = to_categorical(OrdinalEncoder(col))\n",
    "    represented_data = np.concatenate((represented_data, one_hot_encoded), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(represented_data))\n",
    "print(len(represented_data[0]))\n",
    "if len(represented_data[0]) != raw_input_dim:\n",
    "    print(\"Input dimension is wrong!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split all data into training, validation and test sets\n",
    "## Multi-hot encoding for multi-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_hot_encoding(labels):\n",
    "    \"\"\" multi-hot encoding for the labels of each meida post \n",
    "        Args:\n",
    "            labels: list, dimension of rows may not be same\n",
    "        Return:\n",
    "            num_of_classes: int, total number of classes\n",
    "            res: array, num_of_examples x num_of_classes, multi-hot encoded array\n",
    "    \"\"\"\n",
    "    # number of classes\n",
    "    num_examples, min_idx, max_idx = len(labels), float('inf'), -float('inf')\n",
    "    for row in labels:\n",
    "        for col in row:\n",
    "            if col < min_idx:\n",
    "                min_idx = col\n",
    "            if col > max_idx:\n",
    "                max_idx = col\n",
    "    num_of_classes = max_idx - min_idx + 1\n",
    "    \n",
    "    res = np.zeros((num_examples, max_idx-min_idx+1), dtype = int)\n",
    "    for row in range(len(labels)):\n",
    "        lbls = labels[row]\n",
    "        for col in lbls:\n",
    "            res[row, col] = 1\n",
    "    return num_of_classes, res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_str = data.label.values\n",
    "labels = []\n",
    "for str_label in labels_str:\n",
    "    label = [int(i) for i in str_label[1:-1].split(',')]\n",
    "    labels.append(label)\n",
    "\n",
    "num_of_classes, encoded_labels_arr = multi_hot_encoding(labels)\n",
    "represented_data = np.concatenate((represented_data, encoded_labels_arr), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(orig_data, split_ratio, num_of_classes):\n",
    "    \"\"\" Split dataframe into train, validation and test datasets.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(orig_data)\n",
    "    data_after_split, tmp, length = {}, {}, len(orig_data)\n",
    "    \n",
    "    tmp['train'], tmp['val'], tmp['test'] = np.split(\n",
    "        orig_data, [int(split_ratio[0] * length), int(1 - split_ratio[2] * length)], axis=0)\n",
    "    \n",
    "    for sett in ['train', 'val', 'test']:\n",
    "        X = tmp[sett][:, :-num_of_classes]\n",
    "        Y = tmp[sett][:, -num_of_classes:]\n",
    "        data_after_split['X' + '_' + sett] = X\n",
    "        data_after_split['Y' + '_' + sett] = Y\n",
    "\n",
    "    print(data_after_split['X_train'].shape, data_after_split['Y_train'].shape,\n",
    "          data_after_split['X_val'].shape, data_after_split['Y_val'].shape,\n",
    "          data_after_split['X_test'].shape, data_after_split['Y_test'].shape)\n",
    "    return data_after_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(represented_data.shape)\n",
    "data_after_split = split_data(represented_data, SPLIT_RATIO, num_of_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now the tabular data are ready to be fed into embedding layers and feed-forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure reproducible results\n",
    "# https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(42)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# Integer IDs representing 1-hot encodings\n",
    "media_caption_in = Input(shape=(MAX_WORDS_IN_CAPTION,))\n",
    "poster_instagram_username_in = Input(shape=(1,))\n",
    "others_in = Input(shape=(N_poster_account_type + N_media_type + N_caption_type, ))\n",
    "\n",
    "# Two Embedding layers\n",
    "caption_embedding = Embedding(input_dim=vocab_size, output_dim=WORD_EMBEDDING_DIM, \n",
    "                              embeddings_initializer=Constant(embedding_matrix), \n",
    "                              input_length=MAX_WORDS_IN_CAPTION, trainable=True, \n",
    "                              name = 'word_emb')(media_caption_in)\n",
    "\n",
    "ins_username_embedding = Embedding(N_ins_username, INS_USERNAME_EMBEDDING_DIM, \n",
    "                                   name = 'insID_emb')(poster_instagram_username_in)\n",
    "\n",
    "# Reshape and merge all embeddings together\n",
    "avg_caption_embedding = Lambda(lambda x: K.mean(x, axis = 1, keepdims=False))(caption_embedding)\n",
    "\n",
    "reshape_caption_embedding = Reshape(target_shape=(WORD_EMBEDDING_DIM,))\n",
    "reshape_ins_username = Reshape(target_shape=(INS_USERNAME_EMBEDDING_DIM,))\n",
    "\n",
    "combined = concatenate([reshape_caption_embedding(avg_caption_embedding), \n",
    "                  reshape_ins_username(ins_username_embedding), others_in])\n",
    "    \n",
    "\n",
    "\n",
    "# Hidden layers\n",
    "regularizer_param = 0.0003\n",
    "hidden_1 = Dense(64, activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(regularizer_param))(combined)\n",
    "hidden_2 = Dense(32, activation='relu', \n",
    "                 kernel_regularizer=regularizers.l2(regularizer_param))(hidden_1)\n",
    "output = Dense(num_of_classes, activation='sigmoid', \n",
    "               kernel_regularizer=regularizers.l2(regularizer_param))(hidden_2)\n",
    "\n",
    "# Compile with categorical crossentropy and adam\n",
    "model = Model(inputs=[media_caption_in, poster_instagram_username_in, others_in], outputs = [output])\n",
    "\n",
    "##----- Important: In multi-label classification problems. It is -----##\n",
    "##----- easy to obtain high accuracy because of sparsity of labels -----##\n",
    "##----- Use customized metrics: precision, recall, and Exact Match Ratio(Subset accuracy) -----##\n",
    "## https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff\n",
    "#https://stats.stackexchange.com/questions/12702/what-are-the-measure-for-accuracy-of-multilabel-data/168952\n",
    "\n",
    "#There is a difference between the metric on training dataset and on validation dataset. \n",
    "#For the val set the metric is calculated at epoch end for your whole val dataset. \n",
    "#For the train set: The metric is calculated on batch end and the average keeps getting updated till epochs end.\n",
    "#As you can see the metric for the train set is evaluated on the fly with each batch was evaluated using different weights. \n",
    "#That's why the train metric shows sometimes strange behaviour.\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    #Precision metric.\n",
    "    y_pred = K.cast(K.greater(y_pred,0.5),dtype=float)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred))\n",
    "    predicted_positives = K.sum(K.round(y_pred))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    #Recall metric.\n",
    "    y_pred = K.cast(K.greater(y_pred,0.5),dtype=float)\n",
    "    true_positives = K.sum(K.round(y_true * y_pred))\n",
    "    actural_positives = K.sum(K.round(y_true))\n",
    "    recall = true_positives / (actural_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "#def Hamming_loss(y_true, y_pred):\n",
    "#    # y_pred is not filterd by 0.5 yet\n",
    "#    tmp = K.abs(y_true-y_pred)\n",
    "#    return K.mean(K.cast(K.greater(tmp,0.5),dtype=float))\n",
    "\n",
    "def exact_match_ratio(y_true, y_pred):\n",
    "    #pred = tf.equal(tf.round(y_logits), tf.round(y_true))\n",
    "    predictions = tf.to_float(tf.greater_equal(y_pred, 0.5))\n",
    "    pred_match = tf.equal(predictions, tf.round(y_true))\n",
    "    exact_match = tf.reduce_min(tf.to_float(pred_match), axis=1)\n",
    "    return tf.reduce_mean(exact_match)    \n",
    "    \n",
    "model.compile(loss='binary_crossentropy', \n",
    "            optimizer='adam', metrics=[precision, recall, exact_match_ratio])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "val_data = ([data_after_split['X_val'][:, :MAX_WORDS_IN_CAPTION], \n",
    "             data_after_split['X_val'][:,MAX_WORDS_IN_CAPTION], \n",
    "             data_after_split['X_val'][:,MAX_WORDS_IN_CAPTION+1:]],\n",
    "             data_after_split['Y_val'])\n",
    "batchSize = 128\n",
    "\n",
    "history = model.fit([data_after_split['X_train'][:, :MAX_WORDS_IN_CAPTION], \n",
    "                     data_after_split['X_train'][:,MAX_WORDS_IN_CAPTION], \n",
    "                     data_after_split['X_train'][:,MAX_WORDS_IN_CAPTION+1:]],\n",
    "                     data_after_split['Y_train'],\n",
    "                     validation_data = val_data, batch_size=batchSize, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and history\n",
    "with open('DNN_history', 'wb') as fin:\n",
    "        pickle.dump(history.history, fin)\n",
    "model.save('DNN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(y_true, y_pred):\n",
    "    #Precision metric.\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred <0.5] = 0\n",
    "    true_positives = np.sum(y_pred*y_true)\n",
    "    predicted_positives = np.sum(y_pred)\n",
    "    return true_positives / predicted_positives\n",
    "\n",
    "def get_recall(y_true, y_pred):\n",
    "    #Recall metric.\n",
    "    y_pred[y_pred >= 0.5] = 1\n",
    "    y_pred[y_pred <0.5] = 0\n",
    "    true_positives = np.sum(y_pred*y_true)\n",
    "    actural_positives = np.sum(y_true)\n",
    "    return true_positives / actural_positives\n",
    "\n",
    "def get_exact_match_ratio(y_true, y_pred):\n",
    "    match = np.equal(y_pred, y_true)\n",
    "    match = np.amin(match, axis=1)\n",
    "    exact_match_ratio = np.mean(match)\n",
    "    return exact_match_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([data_after_split['X_test'][:, :MAX_WORDS_IN_CAPTION], \n",
    "               data_after_split['X_test'][:,MAX_WORDS_IN_CAPTION], \n",
    "               data_after_split['X_test'][:,MAX_WORDS_IN_CAPTION+1:]])\n",
    "y_true = data_after_split['Y_test']\n",
    "\n",
    "precision, recall,  = get_precision(y_true, y_pred), get_recall(y_true, y_pred)\n",
    "exact_match_ratio = get_exact_match_ratio(y_true, y_pred)\n",
    "\n",
    "print(\"precision, recall and exact match ratio for test set are %.4f, %.4f and %.4f\" \\\n",
    "      %(precision, recall, exact_match_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classID_className = {0: 'color cosmetics:eye:eyebrow', 1: 'skincare:skincare:moisturizer', 2: 'color cosmetics:eye:eyeshadow', 3: 'color cosmetics:eye:mascara', 4: 'accessories:accessories:brush', 5: 'fragrance:fragrance:fragrance', 6: 'skincare:skincare:cleanser', 7: 'accessories:accessories:tool', 8: 'nail:nail:nail polish', 9: 'color cosmetics:eye:eye palette', 10: 'bath body:bath body:wash', 11: 'hair:style:styling products', 12: 'skincare:skincare:treatments', 13: 'color cosmetics:face:powder', 14: 'skincare:skincare:mask', 15: 'bath body:bath body:body lotion', 16: 'hair:cleanse:conditioner', 17: 'color cosmetics:cheek:cheek palette', 18: 'color cosmetics:lip:lipstick', 19: 'hair:treat:hair treatments', 20: 'color cosmetics:cheek:highlighter', 21: 'hair:cleanse:shampoo', 22: 'color cosmetics:face:setting spray', 23: 'color cosmetics:cheek:blush', 24: 'skincare:skincare:face suncare', 25: 'color cosmetics:eye:eyeliner', 26: 'color cosmetics:face:face palette', 27: 'color cosmetics:face:foundation', 28: 'color cosmetics:lip:lip balm', 29: 'skincare:skincare:face mist', 30: 'skincare:skincare:eyecare', 31: 'color cosmetics:eye:lash', 32: 'color cosmetics:lip:lip gloss', 33: 'color cosmetics:face:face primer', 34: 'color cosmetics:face:concealer', 35: 'color cosmetics:cheek:bronzer', 36: 'skincare:skincare:toner', 37: 'color cosmetics:lip:lip liner', 38: 'bath body:bath body:body suncare', 39: 'bath body:bath body:body glitter'}\n",
    "target_names = [i.split(':')[2] for i in classID_className.values()]\n",
    "print(classification_report(y_true, y_pred, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
